{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbfc7e25",
   "metadata": {},
   "source": [
    "<!-- Portada -->\n",
    "#  **Proyecto Final Electiva 3**\n",
    "**Autores:** Sergio Uribe, Ronald Tapias, Oscar Cuadros\n",
    "**Fecha:** 28 de mayo de 2025  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89c176f",
   "metadata": {},
   "source": [
    "<!-- Secci√≥n de c√≥digo 1 -->\n",
    "## üì¶ Importaci√≥n de librer√≠as esenciales y verificaci√≥n de versi√≥n de NumPy\n",
    "\n",
    "- **openai**: Cliente para usar la API de OpenAI.\n",
    "- **os, json, re, warnings, datetime**: Funciones est√°ndar para manejo de archivos, fechas, expresiones regulares y advertencias.\n",
    "- **torch**: PyTorch para manejo de tensores y modelos ML.\n",
    "- **requests**: Para hacer llamadas HTTP a APIs externas.\n",
    "- **fitz (PyMuPDF)**: Para abrir y extraer texto de PDFs.\n",
    "- **numpy**: Para procesamiento num√©rico.  \n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö†Ô∏è Verificaci√≥n y manejo de versi√≥n de NumPy\n",
    "\n",
    "- Si la versi√≥n de NumPy comienza con '2.', deshabilita funcionalidades avanzadas que dependen de `transformers` (problemas de compatibilidad).\n",
    "- Se recomienda usar NumPy 1.26.4 para compatibilidad plena.\n",
    "- Solo se importa `transformers` (incluyendo tokenizer y modelo RoBERTa) si la versi√≥n de NumPy es compatible.\n",
    "- En caso de error al importar transformers, se vuelve a modo simplificado sin `transformers`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "187b0923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versi√≥n de NumPy detectada: 1.26.4\n",
      "NumPy 1.x detectado. Se usar√°n todas las funcionalidades.\n",
      "Transformers cargado correctamente\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import requests\n",
    "import fitz  # PyMuPDF\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import re\n",
    "\n",
    "# Comprobar la versi√≥n de NumPy y mostrar advertencia\n",
    "import numpy as np\n",
    "numpy_version = np.__version__\n",
    "print(f\"Versi√≥n de NumPy detectada: {numpy_version}\")\n",
    "\n",
    "if numpy_version.startswith('2.'):\n",
    "    print(\"Detectado NumPy 2.x - Se usar√° una versi√≥n simplificada sin transformers\")\n",
    "    USE_TRANSFORMERS = False\n",
    "    warnings.warn(\"NumPy 2.x detectado. Algunas funcionalidades avanzadas estar√°n deshabilitadas.\")\n",
    "    print(\"Para resolverlo permanentemente, ejecuta: pip install numpy==1.26.4\")\n",
    "else:\n",
    "    USE_TRANSFORMERS = True\n",
    "    print(\"NumPy 1.x detectado. Se usar√°n todas las funcionalidades.\")\n",
    "    # Solo importar transformers si tenemos NumPy compatible\n",
    "    try:\n",
    "        from transformers import RobertaTokenizer, RobertaForSequenceClassification, pipeline\n",
    "        print(\"Transformers cargado correctamente\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al cargar transformers: {e}\")\n",
    "        USE_TRANSFORMERS = False\n",
    "        print(\"Se usar√° una versi√≥n simplificada sin transformers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1b4db9",
   "metadata": {},
   "source": [
    "<!-- Secci√≥n de c√≥digo 2 -->\n",
    "## üîë Configuraci√≥n de claves API y variables globales para modelos\n",
    "\n",
    "- **openai.api_key**: Clave de API para usar los servicios de OpenAI (modelos GPT, etc.).\n",
    "- **NEWS_API_KEY**: Clave para la API de NewsAPI, usada para obtener noticias.\n",
    "- **GNEWS_API_KEY**: Clave para la API de GNews, alternativa para buscar noticias.\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Variables globales inicializadas en `None`\n",
    "\n",
    "- **tokenizer**: Tokenizador para procesamiento de texto con transformers (RoBERTa).\n",
    "- **model**: Modelo de transformers para clasificaci√≥n de texto (RoBERTa).\n",
    "- **zero_shot_classifier**: Pipeline para clasificaci√≥n sin entrenamiento espec√≠fico (zero-shot).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2719ad49",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = \"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\"\n",
    "\n",
    "NEWS_API_KEY = \"a60047222798471c80fb34ea2639d2fa\"\n",
    "GNEWS_API_KEY = \"d4b0f8b8d7738a13d7323b29b6a517d2\"\n",
    "\n",
    "tokenizer = None\n",
    "model = None\n",
    "zero_shot_classifier = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c1f80b",
   "metadata": {},
   "source": [
    "<!-- Secci√≥n de c√≥digo 3 -->\n",
    "## ü§ñ Inicializaci√≥n de modelos de transformers si est√°n disponibles\n",
    "\n",
    "- Si `USE_TRANSFORMERS` es True (versi√≥n compatible de NumPy y transformers cargados correctamente):\n",
    "  - Se carga el tokenizador y modelo base de **RoBERTa** (`roberta-base`) para tareas de clasificaci√≥n de texto.\n",
    "  - Se inicializa un pipeline de **zero-shot classification** usando el modelo **BART** (`facebook/bart-large-mnli`) para clasificaci√≥n tem√°tica sin entrenamiento espec√≠fico.\n",
    "- Si ocurre alg√∫n error al cargar los modelos, se muestra el error y se desactiva el uso de transformers (`USE_TRANSFORMERS = False`), para que el c√≥digo use una versi√≥n simplificada sin estos modelos avanzados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "425d8ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelos de transformers inicializados correctamente\n"
     ]
    }
   ],
   "source": [
    "if USE_TRANSFORMERS:\n",
    "    try:\n",
    "        # Inicializar modelo RoBERTa para clasificaci√≥n de temas\n",
    "        tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "        model = RobertaForSequenceClassification.from_pretrained('roberta-base')\n",
    "        \n",
    "        # Inicializar pipeline de zero-shot classification para detectar el tema\n",
    "        zero_shot_classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "        print(\"Modelos de transformers inicializados correctamente\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al inicializar modelos: {e}\")\n",
    "        USE_TRANSFORMERS = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae7a29d",
   "metadata": {},
   "source": [
    "<!-- Secci√≥n de c√≥digo 4 -->\n",
    "## üïµÔ∏è Funci√≥n para detectar el tema principal de un texto\n",
    "\n",
    "- **Entrada**: Texto a analizar y lista opcional de temas posibles.\n",
    "- **Salida**: Tema detectado y nivel de confianza.\n",
    "\n",
    "### Modo sin transformers (`USE_TRANSFORMERS == False`):\n",
    "- Se usa un m√©todo b√°sico basado en conteo de coincidencias de palabras clave en el texto (hasta 1000 caracteres).\n",
    "- Se elige el tema con m√°s coincidencias, asignando una confianza calculada.\n",
    "\n",
    "### Modo con transformers:\n",
    "- Se usa el pipeline de **zero-shot classification** (`facebook/bart-large-mnli`) para clasificar el texto en los temas dados.\n",
    "- Se retorna el tema con mayor probabilidad y su confianza.\n",
    "- En caso de error, se retorna tema gen√©rico \"General\" con confianza 0.5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f781ecfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectar_tema(texto, temas_posibles=None):\n",
    "    \"\"\"Detectar el tema principal del texto.\"\"\"\n",
    "    if not temas_posibles:\n",
    "        temas_posibles = [\n",
    "            \"COVID-19\", \"Salud\", \"Pol√≠tica\", \"Econom√≠a\", \"Tecnolog√≠a\", \n",
    "            \"Ciencia\", \"Deportes\", \"Entretenimiento\", \"Educaci√≥n\", \"Medio Ambiente\"\n",
    "        ]\n",
    "    \n",
    "    texto_corto = texto[:1000]  \n",
    "    \n",
    "    if not USE_TRANSFORMERS:\n",
    "        tema_detectado = \"General\"\n",
    "        max_coincidencias = 0\n",
    "        confianza = 0.5  # Confianza por defecto\n",
    "        \n",
    "        for tema in temas_posibles:\n",
    "            palabras_tema = tema.lower().split()\n",
    "            coincidencias = 0\n",
    "            \n",
    "            for palabra in palabras_tema:\n",
    "                if palabra.lower() in texto_corto.lower():\n",
    "                    coincidencias += texto_corto.lower().count(palabra.lower())\n",
    "            \n",
    "            if coincidencias > max_coincidencias:\n",
    "                max_coincidencias = coincidencias\n",
    "                tema_detectado = tema\n",
    "                confianza = min(0.5 + (coincidencias / 10), 0.95)\n",
    "        \n",
    "        return tema_detectado, confianza\n",
    "    \n",
    "    try:\n",
    "        resultado = zero_shot_classifier(texto_corto, temas_posibles)\n",
    "        tema_principal = resultado['labels'][0]\n",
    "        confianza = resultado['scores'][0]\n",
    "        return tema_principal, confianza\n",
    "    except Exception as e:\n",
    "        print(f\"Error al detectar tema con zero-shot: {e}\")\n",
    "        return \"General\", 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5765a55",
   "metadata": {},
   "source": [
    "<!-- Secci√≥n de c√≥digo 5 -->\n",
    "## üìÑ Funci√≥n para extraer texto de un archivo PDF\n",
    "\n",
    "- **Entrada**: Ruta del archivo PDF.\n",
    "- **Proceso**:  \n",
    "  - Abre el PDF usando PyMuPDF (`fitz`).\n",
    "  - Recorre cada p√°gina y extrae su texto.\n",
    "  - Concatena el texto de todas las p√°ginas en una sola cadena.\n",
    "\n",
    "- **Salida**: Texto completo extra√≠do del PDF.  \n",
    "- En caso de error, muestra mensaje y retorna cadena vac√≠a.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "79e98476",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_texto_pdf(path_pdf):\n",
    "    \"\"\"Extraer texto de un archivo PDF.\"\"\"\n",
    "    try:\n",
    "        doc = fitz.open(path_pdf)\n",
    "        texto = \"\"\n",
    "        for pagina in doc:\n",
    "            texto += pagina.get_text()\n",
    "        return texto\n",
    "    except Exception as e:\n",
    "        print(f\"Error al extraer texto del PDF: {e}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fc66f7",
   "metadata": {},
   "source": [
    "<!-- Secci√≥n de c√≥digo 6 -->\n",
    "## üì∞ Funci√≥n para buscar noticias relacionadas con un tema espec√≠fico\n",
    "\n",
    "- **Entrada**:  \n",
    "  - `tema`: palabra o frase para buscar noticias.  \n",
    "  - `cantidad`: n√∫mero m√°ximo de noticias a obtener (por defecto 5).\n",
    "\n",
    "- **Proceso**:  \n",
    "  1. Intenta obtener noticias desde **NewsAPI** usando la clave `NEWS_API_KEY`.  \n",
    "  2. Si no hay resultados o falla, intenta con **GNews** usando `GNEWS_API_KEY`.  \n",
    "  3. Si a√∫n no hay resultados, usa una API p√∫blica alternativa (**Spaceflight News API**) que no requiere clave.  \n",
    "\n",
    "- **Salida**: Lista de diccionarios con informaci√≥n de noticias: t√≠tulo, descripci√≥n, fecha, fuente y URL.\n",
    "\n",
    "- En caso de errores en las APIs, muestra mensajes pero contin√∫a intentando las siguientes fuentes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "14d41f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buscar_noticias(tema, cantidad=5):\n",
    "    \"\"\"Buscar noticias relacionadas con un tema espec√≠fico.\"\"\"\n",
    "    noticias = []\n",
    "    \n",
    "    # Intentar con NewsAPI primero\n",
    "    if NEWS_API_KEY:\n",
    "        try:\n",
    "            url = f\"https://newsapi.org/v2/everything?q={tema}&sortBy=relevancy&pageSize={cantidad}&apiKey={NEWS_API_KEY}&language=es\"\n",
    "            response = requests.get(url)\n",
    "            data = response.json()\n",
    "            \n",
    "            if data.get('status') == 'ok' and data.get('articles'):\n",
    "                for articulo in data['articles'][:cantidad]:\n",
    "                    noticias.append({\n",
    "                        'titulo': articulo.get('title', ''),\n",
    "                        'descripcion': articulo.get('description', ''),\n",
    "                        'fecha': articulo.get('publishedAt', ''),\n",
    "                        'fuente': articulo.get('source', {}).get('name', ''),\n",
    "                        'url': articulo.get('url', '')\n",
    "                    })\n",
    "        except Exception as e:\n",
    "            print(f\"Error con NewsAPI: {e}\")\n",
    "    \n",
    "    # Si no hay resultados o error, intentar con GNews\n",
    "    if not noticias and GNEWS_API_KEY:\n",
    "        try:\n",
    "            url = f\"https://gnews.io/api/v4/search?q={tema}&token={GNEWS_API_KEY}&lang=es&max={cantidad}\"\n",
    "            response = requests.get(url)\n",
    "            data = response.json()\n",
    "            \n",
    "            if data.get('articles'):\n",
    "                for articulo in data['articles'][:cantidad]:\n",
    "                    noticias.append({\n",
    "                        'titulo': articulo.get('title', ''),\n",
    "                        'descripcion': articulo.get('description', ''),\n",
    "                        'fecha': articulo.get('publishedAt', ''),\n",
    "                        'fuente': articulo.get('source', {}).get('name', ''),\n",
    "                        'url': articulo.get('url', '')\n",
    "                    })\n",
    "        except Exception as e:\n",
    "            print(f\"Error con GNews: {e}\")\n",
    "    \n",
    "    # Si todav√≠a no hay resultados, usar API p√∫blica alternativa\n",
    "    if not noticias:\n",
    "        try:\n",
    "            url = f\"https://api.spaceflightnewsapi.net/v3/articles?_limit={cantidad}&title_contains={tema}\"\n",
    "            response = requests.get(url)\n",
    "            data = response.json()\n",
    "            \n",
    "            for articulo in data[:cantidad]:\n",
    "                noticias.append({\n",
    "                    'titulo': articulo.get('title', ''),\n",
    "                    'descripcion': articulo.get('summary', ''),\n",
    "                    'fecha': articulo.get('publishedAt', ''),\n",
    "                    'fuente': articulo.get('newsSite', ''),\n",
    "                    'url': articulo.get('url', '')\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"Error con API de noticias alternativa: {e}\")\n",
    "    \n",
    "    return noticias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616a059c",
   "metadata": {},
   "source": [
    "<!-- Secci√≥n de c√≥digo 7 -->\n",
    "## üòä Funci√≥n para analizar el sentimiento de un texto\n",
    "\n",
    "- **Modo sin transformers** (`USE_TRANSFORMERS == False`):  \n",
    "  - Utiliza una lista simple de palabras positivas y negativas para contar ocurrencias en el texto (sin contexto ni aprendizaje).  \n",
    "  - Retorna sentimiento basado en cu√°l grupo tiene m√°s coincidencias y una confianza calculada.\n",
    "\n",
    "- **Modo con transformers** (`USE_TRANSFORMERS == True`):  \n",
    "  - Usa el tokenizador y modelo de **RoBERTa** para clasificaci√≥n de sentimiento.  \n",
    "  - Convierte el texto a tensores, obtiene logits, calcula probabilidades y predice el sentimiento con mayor confianza.  \n",
    "  - Mapea la predicci√≥n a etiquetas: 0 = positivo, 1 = negativo, otros casos a neutral.\n",
    "\n",
    "- En caso de error en el modelo, retorna sentimiento neutral con confianza est√°ndar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "51ac8569",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analizar_sentimiento(texto):\n",
    "    \"\"\"Analizar el sentimiento del texto.\"\"\"\n",
    "    if not USE_TRANSFORMERS:\n",
    "        # Implementaci√≥n alternativa de an√°lisis de sentimiento usando palabras clave\n",
    "        palabras_positivas = ['bueno', 'excelente', 'genial', 'incre√≠ble', 'positivo', '√©xito', 'feliz', 'alegre', 'satisfecho']\n",
    "        palabras_negativas = ['malo', 'terrible', 'horrible', 'negativo', 'fracaso', 'triste', 'infeliz', 'insatisfecho']\n",
    "        \n",
    "        texto_lower = texto.lower()\n",
    "        count_pos = sum(texto_lower.count(p) for p in palabras_positivas)\n",
    "        count_neg = sum(texto_lower.count(n) for n in palabras_negativas)\n",
    "        \n",
    "        if count_pos > count_neg:\n",
    "            return \"positivo\", 0.5 + min(count_pos / (count_pos + count_neg + 1), 0.45)\n",
    "        elif count_neg > count_pos:\n",
    "            return \"negativo\", 0.5 + min(count_neg / (count_pos + count_neg + 1), 0.45)\n",
    "        else:\n",
    "            return \"neutral\", 0.5\n",
    "    \n",
    "    # Usar RoBERTa si est√° disponible\n",
    "    try:\n",
    "        inputs = tokenizer(texto, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        pred = torch.argmax(probs).item()\n",
    "        conf = probs[0, pred].item()\n",
    "        \n",
    "        sentimiento = \"neutral\"\n",
    "        if pred == 0:\n",
    "            sentimiento = \"positivo\"\n",
    "        elif pred == 1:\n",
    "            sentimiento = \"negativo\"\n",
    "        \n",
    "        return sentimiento, conf\n",
    "    except Exception as e:\n",
    "        print(f\"Error al analizar sentimiento con RoBERTa: {e}\")\n",
    "        return \"neutral\", 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d900c28f",
   "metadata": {},
   "source": [
    "<!-- Secci√≥n de c√≥digo 8 -->\n",
    "## ‚úÖ Funci√≥n para verificar la veracidad de un texto usando GPT-4\n",
    "\n",
    "- **Entrada**:  \n",
    "  - `texto`: texto a analizar.  \n",
    "  - `tema` (opcional): contexto tem√°tico para ayudar en la verificaci√≥n.\n",
    "\n",
    "- **Proceso**:  \n",
    "  - Limita el texto a 4000 caracteres para evitar exceso de tokens.  \n",
    "  - Construye un prompt detallado para pedir al modelo GPT-4 que analice:  \n",
    "    1) si el texto tiene informaci√≥n falsa o enga√±osa,  \n",
    "    2) cu√°les afirmaciones espec√≠ficas son falsas,  \n",
    "    3) explicaci√≥n de falsedades,  \n",
    "    4) contradicciones internas,  \n",
    "    5) puntuaci√≥n de veracidad (0 a 100).  \n",
    "  - Env√≠a la petici√≥n a OpenAI con temperatura baja para respuestas m√°s precisas.  \n",
    "  - Extrae la puntuaci√≥n y clasifica la veracidad en categor√≠as (Verdadero, Mayormente verdadero, etc.).  \n",
    "  - Intenta extraer afirmaciones falsas del texto generado por GPT-4.  \n",
    "  - Devuelve un diccionario con la categor√≠a de veracidad, confianza num√©rica, razones (afirmaciones falsas) y el an√°lisis completo.\n",
    "\n",
    "- **Manejo de errores**:  \n",
    "  - En caso de excepci√≥n, retorna estado de error con informaci√≥n del fallo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "da0b57c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verificar_veracidad(texto, tema=None):\n",
    "    \"\"\"Verificar la veracidad de un texto usando GPT-4.\"\"\"\n",
    "    if not texto:\n",
    "        return {\"veracidad\": \"No determinable\", \"confianza\": 0, \"razones\": [\"Texto vac√≠o\"], \"fuentes_contradictorias\": []}\n",
    "        \n",
    "    texto_analizar = texto[:4000] if len(texto) > 4000 else texto\n",
    "    prompt = f\"\"\"Analiza el siguiente texto y determina su veracidad. \n",
    "    Identifica afirmaciones falsas, enga√±osas o inexactas. \n",
    "    Proporciona un an√°lisis detallado que incluya:\n",
    "    1. Si el texto contiene informaci√≥n falsa o enga√±osa\n",
    "    2. Qu√© afirmaciones espec√≠ficas son falsas o enga√±osas\n",
    "    3. La explicaci√≥n de por qu√© son falsas\n",
    "    4. Cualquier contradicci√≥n interna en el texto\n",
    "    5. Una puntuaci√≥n de veracidad del 0 al 100\n",
    "\n",
    "    Texto para analizar:\n",
    "    \"\"\"\n",
    "    if tema:\n",
    "        prompt += f\"\\nTema: {tema}\\n\"\n",
    "    prompt += f\"\\n{texto_analizar}\"\n",
    "    \n",
    "    try:\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"Eres un verificador de hechos experto. Tu tarea es analizar textos para determinar su veracidad, identificar informaci√≥n falsa o enga√±osa, y explicar por qu√©. Tus respuestas deben seguir un formato estructurado que incluya: 1) Veredicto de veracidad, 2) Afirmaciones falsas identificadas, 3) Explicaci√≥n de cada falsedad, 4) Puntuaci√≥n de veracidad.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "        response = openai.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=messages,\n",
    "            max_tokens=800,\n",
    "            temperature=0.3\n",
    "        )\n",
    "        analisis = response.choices[0].message.content\n",
    "        patron_puntuacion = r\"(?:puntuaci[o√≥]n|veracidad).*?(?:de|es).*?(\\d+)\"\n",
    "        match_puntuacion = re.search(patron_puntuacion, analisis.lower())\n",
    "        puntuacion = int(match_puntuacion.group(1)) if match_puntuacion else 50\n",
    "        categoria = \"No determinable\"\n",
    "        if puntuacion >= 80:\n",
    "            categoria = \"Verdadero\"\n",
    "        elif puntuacion >= 60:\n",
    "            categoria = \"Mayormente verdadero\"\n",
    "        elif puntuacion >= 40:\n",
    "            categoria = \"Parcialmente verdadero\"\n",
    "        elif puntuacion >= 20:\n",
    "            categoria = \"Mayormente falso\"\n",
    "        else:\n",
    "            categoria = \"Falso\"\n",
    "        patron_afirmaciones = r\"(?:afirmaci[o√≥]n(?:es)? falsa(?:s)?|informaci[o√≥]n falsa)[:\\s]*([^\\n.]*)\"\n",
    "        match_afirmaciones = re.search(patron_afirmaciones, analisis.lower())\n",
    "        afirmaciones_falsas = []\n",
    "        if match_afirmaciones:\n",
    "            afirmaciones_falsas = [a.strip() for a in re.split(r\"[\\n\\d\\.\\-‚Ä¢]+\", match_afirmaciones.group(1)) if a.strip()]\n",
    "        if not afirmaciones_falsas and puntuacion < 60:\n",
    "            afirmaciones_falsas = [\"El an√°lisis detect√≥ contenido cuestionable pero no especific√≥ afirmaciones concretas\"]\n",
    "        return {\n",
    "            \"veracidad\": categoria,\n",
    "            \"confianza\": puntuacion/100,\n",
    "            \"razones\": afirmaciones_falsas,\n",
    "            \"analisis_completo\": analisis\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error al verificar veracidad: {e}\")\n",
    "        return {\"veracidad\": \"Error en an√°lisis\", \"confianza\": 0, \"razones\": [f\"Error: {e}\"], \"analisis_completo\": \"\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edb5890",
   "metadata": {},
   "source": [
    "<!-- Secci√≥n de c√≥digo 9 -->\n",
    "## üì∞ Funci√≥n para verificar la veracidad de una noticia espec√≠fica\n",
    "\n",
    "- **Entrada**: Diccionario `noticia` con campos t√≠picos: t√≠tulo, descripci√≥n, fuente y fecha.\n",
    "- **Proceso**:  \n",
    "  - Valida que la entrada sea un diccionario v√°lido.  \n",
    "  - Construye un texto concatenado con la informaci√≥n relevante de la noticia.  \n",
    "  - Llama a la funci√≥n `verificar_veracidad` para analizar el texto completo y evaluar su veracidad.\n",
    "\n",
    "- **Salida**: Resultado estructurado de la funci√≥n `verificar_veracidad` con veredicto, confianza, razones y an√°lisis completo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3e24ac31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verificar_noticia(noticia):\n",
    "    \"\"\"Verificar la veracidad de una noticia espec√≠fica.\"\"\"\n",
    "    if not noticia or not isinstance(noticia, dict):\n",
    "        return {\"veracidad\": \"No determinable\", \"confianza\": 0, \"razones\": [\"Formato de noticia inv√°lido\"]}\n",
    "    texto_analizar = f\"T√≠tulo: {noticia.get('titulo','')}\\n\\n\"\n",
    "    texto_analizar += f\"Descripci√≥n: {noticia.get('descripcion','')}\\n\\n\"\n",
    "    texto_analizar += f\"Fuente: {noticia.get('fuente','')}\\n\"\n",
    "    texto_analizar += f\"Fecha: {noticia.get('fecha','')}\\n\"\n",
    "    return verificar_veracidad(texto_analizar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbaf203",
   "metadata": {},
   "source": [
    "<!-- Secci√≥n de c√≥digo 10 -->\n",
    "## üìã Funci√≥n para extraer afirmaciones principales verificables de un texto\n",
    "\n",
    "- **Entrada**:  \n",
    "  - `texto`: texto completo a analizar.  \n",
    "  - `cantidad`: n√∫mero m√°ximo de afirmaciones a extraer (por defecto 5).\n",
    "\n",
    "- **Proceso**:  \n",
    "  - Valida que el texto tenga suficiente longitud (>50 caracteres).  \n",
    "  - Recorta el texto a m√°ximo 3000 caracteres para no exceder l√≠mite de tokens.  \n",
    "  - Solicita a GPT-4 (modelo `gpt-4o-mini`) que devuelva solo una lista numerada con las afirmaciones m√°s importantes o controvertidas para verificar.  \n",
    "  - Extrae esas afirmaciones con expresiones regulares para numeraci√≥n.  \n",
    "\n",
    "- **Salida**: Lista con las afirmaciones extra√≠das (m√°ximo `cantidad`).  \n",
    "- En caso de error, retorna lista vac√≠a y muestra el error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7b450b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_afirmaciones(texto, cantidad=5):\n",
    "    \"\"\"Extraer afirmaciones principales de un texto para verificaci√≥n.\"\"\"\n",
    "    if not texto or len(texto) < 50:\n",
    "        return []\n",
    "    texto_corto = texto[:3000] if len(texto) > 3000 else texto\n",
    "    try:\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"Extrae las principales afirmaciones verificables del siguiente texto. Devuelve SOLO una lista numerada de las 5 afirmaciones m√°s importantes o controvertidas que requieren verificaci√≥n de hechos. No incluyas opiniones o juicios de valor.\"},\n",
    "            {\"role\": \"user\", \"content\": texto_corto}\n",
    "        ]\n",
    "        response = openai.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=messages,\n",
    "            max_tokens=300,\n",
    "            temperature=0.3\n",
    "        )\n",
    "        resultado = response.choices[0].message.content\n",
    "        afirmaciones = []\n",
    "        for line in resultado.strip().split('\\n'):\n",
    "            match = re.match(r'^\\d+\\.\\s*(.+)$', line.strip())\n",
    "            if match:\n",
    "                afirmaciones.append(match.group(1).strip())\n",
    "        return afirmaciones[:cantidad]\n",
    "    except Exception as e:\n",
    "        print(f\"Error al extraer afirmaciones: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2606308",
   "metadata": {},
   "source": [
    "<!-- Secci√≥n de c√≥digo 11 -->\n",
    "## üîç Funci√≥n para verificar la veracidad de una afirmaci√≥n espec√≠fica\n",
    "\n",
    "- **Entrada**:  \n",
    "  - `afirmacion`: texto con la afirmaci√≥n a verificar.  \n",
    "  - `tema` (opcional): contexto tem√°tico para mejorar el an√°lisis.\n",
    "\n",
    "- **Proceso**:  \n",
    "  - Valida que la afirmaci√≥n no est√© vac√≠a.  \n",
    "  - Construye un prompt para GPT-4 pidi√©ndole que determine si la afirmaci√≥n es Verdadera, Falsa, Parcialmente verdadera o No verificable, con explicaci√≥n.  \n",
    "  - Env√≠a el prompt al modelo `gpt-4o-mini`.  \n",
    "  - Extrae el veredicto del texto devuelto usando expresiones regulares.  \n",
    "  - Retorna un diccionario con el veredicto y la explicaci√≥n completa.\n",
    "\n",
    "- **Manejo de errores**:  \n",
    "  - En caso de excepci√≥n, devuelve un resultado de error con mensaje.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b2c5ae91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verificar_afirmacion(afirmacion, tema=None):\n",
    "    \"\"\"Verificar una afirmaci√≥n espec√≠fica.\"\"\"\n",
    "    if not afirmacion:\n",
    "        return {\"veracidad\": \"No determinable\", \"explicacion\": \"Afirmaci√≥n vac√≠a\"}\n",
    "    try:\n",
    "        prompt = f\"Verifica la siguiente afirmaci√≥n y determina si es verdadera, falsa o no verificable.\"\n",
    "        if tema:\n",
    "            prompt += f\"\\n\\nContexto: La afirmaci√≥n est√° relacionada con el tema de '{tema}'.\"\n",
    "        prompt += f\"\\n\\nAfirmaci√≥n: '{afirmacion}'\"\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"Eres un verificador de hechos experto. Tu tarea es analizar una afirmaci√≥n y determinar su veracidad bas√°ndote en hechos verificables. Da un veredicto claro (Verdadero/Falso/Parcialmente verdadero/No verificable) seguido de una explicaci√≥n concisa.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "        response = openai.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=messages,\n",
    "            max_tokens=300,\n",
    "            temperature=0.3\n",
    "        )\n",
    "        resultado = response.choices[0].message.content\n",
    "        match = re.search(r\"(verdadero|falso|parcialmente verdadero|no verificable)\", resultado.lower())\n",
    "        veredicto = \"No determinable\"\n",
    "        if match:\n",
    "            t = match.group(1)\n",
    "            if \"falso\" in t and \"parcialmente\" not in t:\n",
    "                veredicto = \"Falso\"\n",
    "            elif \"verdadero\" in t and \"parcialmente\" not in t:\n",
    "                veredicto = \"Verdadero\"\n",
    "            elif \"parcialmente\" in t:\n",
    "                veredicto = \"Parcialmente verdadero\"\n",
    "            elif \"no verificable\" in t:\n",
    "                veredicto = \"No verificable\"\n",
    "        return {\"veracidad\": veredicto, \"explicacion\": resultado}\n",
    "    except Exception as e:\n",
    "        print(f\"Error al verificar afirmaci√≥n: {e}\")\n",
    "        return {\"veracidad\": \"Error en an√°lisis\", \"explicacion\": f\"Error: {e}\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedd0276",
   "metadata": {},
   "source": [
    "<!-- Secci√≥n de c√≥digo 12 -->\n",
    "## üí¨ Chatbot tem√°tico con opci√≥n de verificaci√≥n de hechos\n",
    "\n",
    "- **Entrada**:  \n",
    "  - `pregunta`: consulta del usuario.  \n",
    "  - `tema`: tema espec√≠fico para contextualizar la respuesta (por defecto \"General\").  \n",
    "  - `contexto_texto`: texto adicional para contexto (por ejemplo, texto extra√≠do de un PDF).  \n",
    "  - `noticias`: lista de noticias recientes relacionadas para enriquecer la respuesta.  \n",
    "  - `verificar`: booleano para activar verificaci√≥n de hechos en la respuesta.\n",
    "\n",
    "- **Proceso**:  \n",
    "  - Construye un prompt que incluye tema, contexto resumido, y noticias recientes (m√°ximo 3).  \n",
    "  - Ajusta las instrucciones del sistema seg√∫n si se activa la verificaci√≥n de hechos, solicitando an√°lisis cr√≠tico y aclaraci√≥n sobre informaci√≥n cuestionable.  \n",
    "  - Env√≠a la consulta al modelo GPT-4 (`gpt-4o-mini`) para generar respuesta.  \n",
    "  - Captura errores y devuelve un mensaje adecuado en caso de fallo.\n",
    "\n",
    "- **Salida**: Texto generado como respuesta a la pregunta, contextualizado y opcionalmente verificado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "12e5d750",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot_tematico(pregunta, tema=\"General\", contexto_texto=None, noticias=None, verificar=False):\n",
    "    \"\"\"Chatbot que proporciona respuestas basadas en temas espec√≠ficos.\"\"\"\n",
    "    prompt = f\"Tema: {tema}\\n\"\n",
    "    if contexto_texto:\n",
    "        contexto_resumido = contexto_texto[:2000] + \"...\" if len(contexto_texto) > 2000 else contexto_texto\n",
    "        prompt += f\"Contexto del documento:\\n{contexto_resumido}\\n\\n\"\n",
    "    if noticias:\n",
    "        prompt += \"Noticias recientes sobre este tema:\\n\"\n",
    "        for i, noticia in enumerate(noticias[:3], 1):\n",
    "            prompt += f\"{i}. {noticia['titulo']} - {noticia['descripcion']}\\n\"\n",
    "        prompt += \"\\n\"\n",
    "    system_content = f\"Eres un asistente experto en {tema}. Proporciona informaci√≥n precisa basada en los datos disponibles.\"\n",
    "    if verificar:\n",
    "        system_content = f\"Eres un asistente experto en {tema} con capacidades de verificaci√≥n de hechos. Analiza cr√≠ticamente la informaci√≥n proporcionada. Identifica posibles afirmaciones falsas o enga√±osas y verifica su veracidad antes de responder. Al responder, indica claramente qu√© informaci√≥n es verificable y cu√°l podr√≠a ser cuestionable.\"\n",
    "        prompt += \"\\nIMPORTANTE: Verifica la veracidad de tu respuesta. Indica expl√≠citamente cuando la informaci√≥n pueda ser cuestionable o no verificable.\"\n",
    "    prompt += f\"\\nPregunta: {pregunta}\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_content},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    try:\n",
    "        response = openai.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=messages,\n",
    "            max_tokens=500,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"Error al generar respuesta: {e}\")\n",
    "        return f\"Lo siento, ocurri√≥ un error al generar la respuesta: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2966d552",
   "metadata": {},
   "source": [
    "<!-- Secci√≥n de c√≥digo 15 -->\n",
    "## üìä Funci√≥n para an√°lisis masivo de archivos y evaluaci√≥n del rendimiento del modelo de veracidad\n",
    "\n",
    "- **Entrada**:  \n",
    "  - `directorio_verdaderas`: carpeta con archivos de noticias verdaderas.  \n",
    "  - `directorio_falsas`: carpeta con archivos de noticias falsas.  \n",
    "  - `max_archivos`: n√∫mero m√°ximo de archivos a analizar por carpeta (por defecto 10).\n",
    "\n",
    "- **Proceso**:  \n",
    "  - Lee archivos (txt o pdf) de cada carpeta.  \n",
    "  - Para cada archivo:  \n",
    "    - Extrae texto (PDF o texto plano).  \n",
    "    - Detecta el tema con `detectar_tema`.  \n",
    "    - Verifica la veracidad con `verificar_veracidad`.  \n",
    "    - Clasifica como correcto o incorrecto seg√∫n la confianza y si el archivo es verdadero o falso.  \n",
    "    - Registra detalles y actualiza matriz de confusi√≥n:  \n",
    "      - VP: Verdadero Positivo, VN: Verdadero Negativo, FP: Falso Positivo, FN: Falso Negativo.  \n",
    "  - Calcula m√©tricas comunes de evaluaci√≥n: precisi√≥n, recall, F1-score y exactitud (accuracy).\n",
    "\n",
    "- **Salida**: Diccionario con resultados detallados, m√©tricas y matriz de confusi√≥n para an√°lisis del desempe√±o.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c6ecac2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analisis_masivo_archivos(directorio_verdaderas, directorio_falsas, max_archivos=10):\n",
    "    \"\"\"Analizar m√∫ltiples archivos para evaluar rendimiento del modelo de veracidad.\"\"\"\n",
    "    import glob\n",
    "    \n",
    "    def leer_archivo(ruta):\n",
    "        \"\"\"Leer contenido de archivo (txt o pdf).\"\"\"\n",
    "        try:\n",
    "            if ruta.lower().endswith('.pdf'):\n",
    "                return extraer_texto_pdf(ruta)\n",
    "            else:\n",
    "                with open(ruta, 'r', encoding='utf-8') as f:\n",
    "                    return f.read()\n",
    "        except Exception as e:\n",
    "            print(f\"Error leyendo {ruta}: {e}\")\n",
    "            return \"\"\n",
    "    \n",
    "    resultados = {\n",
    "        'verdaderas': {'archivos': [], 'correctos': 0, 'incorrectos': 0, 'detalles': []},\n",
    "        'falsas': {'archivos': [], 'correctos': 0, 'incorrectos': 0, 'detalles': []},\n",
    "        'metricas': {},\n",
    "        'confusion_matrix': {'VP': 0, 'VN': 0, 'FP': 0, 'FN': 0}\n",
    "    }\n",
    "    \n",
    "    print(\"üîç Iniciando an√°lisis masivo de archivos...\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Procesar archivos verdaderos\n",
    "    print(f\"\\nüì∞ Analizando archivos de noticias VERDADERAS...\")\n",
    "    archivos_verdaderos = glob.glob(os.path.join(directorio_verdaderas, \"*\"))[:max_archivos]\n",
    "    \n",
    "    for i, archivo in enumerate(archivos_verdaderos, 1):\n",
    "        print(f\"  [{i}/{len(archivos_verdaderos)}] Procesando: {os.path.basename(archivo)}\")\n",
    "        contenido = leer_archivo(archivo)\n",
    "        \n",
    "        if contenido:\n",
    "            tema_detectado, conf_tema = detectar_tema(contenido)\n",
    "            resultado_verificacion = verificar_veracidad(contenido, tema=tema_detectado)\n",
    "            \n",
    "            # Clasificar como correcto si veracidad >= 60% (Verdadero o Mayormente verdadero)\n",
    "            es_correcto = resultado_verificacion['confianza'] >= 0.6\n",
    "            \n",
    "            detalle = {\n",
    "                'archivo': os.path.basename(archivo),\n",
    "                'tema': tema_detectado,\n",
    "                'confianza_tema': conf_tema,\n",
    "                'veracidad': resultado_verificacion['veracidad'],\n",
    "                'confianza_veracidad': resultado_verificacion['confianza'],\n",
    "                'clasificacion_correcta': es_correcto,\n",
    "                'contenido_preview': contenido[:200] + \"...\" if len(contenido) > 200 else contenido\n",
    "            }\n",
    "            \n",
    "            resultados['verdaderas']['detalles'].append(detalle)\n",
    "            \n",
    "            if es_correcto:\n",
    "                resultados['verdaderas']['correctos'] += 1\n",
    "                resultados['confusion_matrix']['VP'] += 1  # Verdadero Positivo\n",
    "            else:\n",
    "                resultados['verdaderas']['incorrectos'] += 1\n",
    "                resultados['confusion_matrix']['FN'] += 1  # Falso Negativo\n",
    "    \n",
    "    # Procesar archivos falsos\n",
    "    print(f\"\\nüö´ Analizando archivos de noticias FALSAS...\")\n",
    "    archivos_falsos = glob.glob(os.path.join(directorio_falsas, \"*\"))[:max_archivos]\n",
    "    \n",
    "    for i, archivo in enumerate(archivos_falsos, 1):\n",
    "        print(f\"  [{i}/{len(archivos_falsos)}] Procesando: {os.path.basename(archivo)}\")\n",
    "        contenido = leer_archivo(archivo)\n",
    "        \n",
    "        if contenido:\n",
    "            tema_detectado, conf_tema = detectar_tema(contenido)\n",
    "            resultado_verificacion = verificar_veracidad(contenido, tema=tema_detectado)\n",
    "            \n",
    "            # Clasificar como correcto si veracidad < 60% (Falso, Mayormente falso, Parcialmente verdadero)\n",
    "            es_correcto = resultado_verificacion['confianza'] < 0.6\n",
    "            \n",
    "            detalle = {\n",
    "                'archivo': os.path.basename(archivo),\n",
    "                'tema': tema_detectado,\n",
    "                'confianza_tema': conf_tema,\n",
    "                'veracidad': resultado_verificacion['veracidad'],\n",
    "                'confianza_veracidad': resultado_verificacion['confianza'],\n",
    "                'clasificacion_correcta': es_correcto,\n",
    "                'contenido_preview': contenido[:200] + \"...\" if len(contenido) > 200 else contenido\n",
    "            }\n",
    "            \n",
    "            resultados['falsas']['detalles'].append(detalle)\n",
    "            \n",
    "            if es_correcto:\n",
    "                resultados['falsas']['correctos'] += 1\n",
    "                resultados['confusion_matrix']['VN'] += 1  # Verdadero Negativo\n",
    "            else:\n",
    "                resultados['falsas']['incorrectos'] += 1\n",
    "                resultados['confusion_matrix']['FP'] += 1  # Falso Positivo\n",
    "    \n",
    "    # Calcular m√©tricas de rendimiento\n",
    "    cm = resultados['confusion_matrix']\n",
    "    total = cm['VP'] + cm['VN'] + cm['FP'] + cm['FN']\n",
    "    \n",
    "    if total > 0:\n",
    "        precision = cm['VP'] / (cm['VP'] + cm['FP']) if (cm['VP'] + cm['FP']) > 0 else 0\n",
    "        recall = cm['VP'] / (cm['VP'] + cm['FN']) if (cm['VP'] + cm['FN']) > 0 else 0\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        accuracy = (cm['VP'] + cm['VN']) / total\n",
    "        \n",
    "        resultados['metricas'] = {\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1_score,\n",
    "            'accuracy': accuracy,\n",
    "            'total_archivos': total\n",
    "        }\n",
    "    \n",
    "    return resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766e37c1",
   "metadata": {},
   "source": [
    "<!-- Secci√≥n de c√≥digo 13.6 -->\n",
    "## üìà Funci√≥n para generar reporte detallado del an√°lisis masivo\n",
    "\n",
    "- **Entrada**: Diccionario `resultados` del an√°lisis masivo.\n",
    "- **Proceso**:  \n",
    "  - Muestra estad√≠sticas generales de rendimiento.\n",
    "  - Presenta matriz de confusi√≥n con m√©tricas.\n",
    "  - Lista archivos correctamente e incorrectamente clasificados.\n",
    "  - Genera an√°lisis de temas m√°s frecuentes.\n",
    "  - Identifica patrones en clasificaciones err√≥neas.\n",
    "\n",
    "- **Salida**: Reporte completo formateado para consola con estad√≠sticas y recomendaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "47d91bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostrar_reporte_analisis(resultados):\n",
    "    \"\"\"Mostrar reporte detallado del an√°lisis masivo.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üìä REPORTE DETALLADO DE AN√ÅLISIS DE VERACIDAD\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Estad√≠sticas generales\n",
    "    total_verdaderas = len(resultados['verdaderas']['detalles'])\n",
    "    total_falsas = len(resultados['falsas']['detalles'])\n",
    "    correctos_verdaderas = resultados['verdaderas']['correctos']\n",
    "    correctos_falsas = resultados['falsas']['correctos']\n",
    "    \n",
    "    print(f\"\\nüìà ESTAD√çSTICAS GENERALES:\")\n",
    "    print(f\"   ‚Ä¢ Total de archivos analizados: {total_verdaderas + total_falsas}\")\n",
    "    print(f\"   ‚Ä¢ Archivos de noticias verdaderas: {total_verdaderas}\")\n",
    "    print(f\"   ‚Ä¢ Archivos de noticias falsas: {total_falsas}\")\n",
    "    print(f\"   ‚Ä¢ Clasificaciones correctas: {correctos_verdaderas + correctos_falsas}\")\n",
    "    print(f\"   ‚Ä¢ Tasa de acierto general: {((correctos_verdaderas + correctos_falsas) / (total_verdaderas + total_falsas) * 100):.1f}%\")\n",
    "    \n",
    "    # M√©tricas de rendimiento\n",
    "    if 'metricas' in resultados and resultados['metricas']:\n",
    "        metricas = resultados['metricas']\n",
    "        print(f\"\\nüéØ M√âTRICAS DE RENDIMIENTO:\")\n",
    "        print(f\"   ‚Ä¢ Precisi√≥n: {metricas['precision']:.3f} ({metricas['precision']*100:.1f}%)\")\n",
    "        print(f\"   ‚Ä¢ Recall (Sensibilidad): {metricas['recall']:.3f} ({metricas['recall']*100:.1f}%)\")\n",
    "        print(f\"   ‚Ä¢ F1-Score: {metricas['f1_score']:.3f} ({metricas['f1_score']*100:.1f}%)\")\n",
    "        print(f\"   ‚Ä¢ Exactitud: {metricas['accuracy']:.3f} ({metricas['accuracy']*100:.1f}%)\")\n",
    "    \n",
    "    # Matriz de confusi√≥n\n",
    "    cm = resultados['confusion_matrix']\n",
    "    print(f\"\\nüî¢ MATRIZ DE CONFUSI√ìN:\")\n",
    "    print(f\"   ‚Ä¢ Verdaderos Positivos (VP): {cm['VP']} - Noticias verdaderas correctamente identificadas\")\n",
    "    print(f\"   ‚Ä¢ Verdaderos Negativos (VN): {cm['VN']} - Noticias falsas correctamente identificadas\")\n",
    "    print(f\"   ‚Ä¢ Falsos Positivos (FP): {cm['FP']} - Noticias falsas clasificadas como verdaderas\")\n",
    "    print(f\"   ‚Ä¢ Falsos Negativos (FN): {cm['FN']} - Noticias verdaderas clasificadas como falsas\")\n",
    "    \n",
    "    # An√°lisis detallado por categor√≠a\n",
    "    print(f\"\\n‚úÖ AN√ÅLISIS DE NOTICIAS VERDADERAS:\")\n",
    "    if total_verdaderas > 0:\n",
    "        print(f\"   ‚Ä¢ Correctamente clasificadas: {correctos_verdaderas}/{total_verdaderas} ({correctos_verdaderas/total_verdaderas*100:.1f}%)\")\n",
    "        print(f\"   ‚Ä¢ Incorrectamente clasificadas: {total_verdaderas - correctos_verdaderas}/{total_verdaderas} ({(total_verdaderas - correctos_verdaderas)/total_verdaderas*100:.1f}%)\")\n",
    "        \n",
    "        # Mostrar archivos mal clasificados\n",
    "        incorrectos = [d for d in resultados['verdaderas']['detalles'] if not d['clasificacion_correcta']]\n",
    "        if incorrectos:\n",
    "            print(f\"   \\n   ‚ö†Ô∏è Archivos verdaderos mal clasificados como falsos:\")\n",
    "            for archivo in incorrectos:\n",
    "                print(f\"      - {archivo['archivo']}: {archivo['veracidad']} (confianza: {archivo['confianza_veracidad']*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\n‚ùå AN√ÅLISIS DE NOTICIAS FALSAS:\")\n",
    "    if total_falsas > 0:\n",
    "        print(f\"   ‚Ä¢ Correctamente clasificadas: {correctos_falsas}/{total_falsas} ({correctos_falsas/total_falsas*100:.1f}%)\")\n",
    "        print(f\"   ‚Ä¢ Incorrectamente clasificadas: {total_falsas - correctos_falsas}/{total_falsas} ({(total_falsas - correctos_falsas)/total_falsas*100:.1f}%)\")\n",
    "        \n",
    "        # Mostrar archivos mal clasificados\n",
    "        incorrectos = [d for d in resultados['falsas']['detalles'] if not d['clasificacion_correcta']]\n",
    "        if incorrectos:\n",
    "            print(f\"   \\n   ‚ö†Ô∏è Archivos falsos mal clasificados como verdaderos:\")\n",
    "            for archivo in incorrectos:\n",
    "                print(f\"      - {archivo['archivo']}: {archivo['veracidad']} (confianza: {archivo['confianza_veracidad']*100:.1f}%)\")\n",
    "    \n",
    "    # An√°lisis de temas\n",
    "    todos_detalles = resultados['verdaderas']['detalles'] + resultados['falsas']['detalles']\n",
    "    temas = {}\n",
    "    for detalle in todos_detalles:\n",
    "        tema = detalle['tema']\n",
    "        if tema not in temas:\n",
    "            temas[tema] = {'total': 0, 'correctos': 0}\n",
    "        temas[tema]['total'] += 1\n",
    "        if detalle['clasificacion_correcta']:\n",
    "            temas[tema]['correctos'] += 1\n",
    "    \n",
    "    print(f\"\\nüè∑Ô∏è AN√ÅLISIS POR TEMAS:\")\n",
    "    for tema, stats in temas.items():\n",
    "        precision_tema = (stats['correctos'] / stats['total'] * 100) if stats['total'] > 0 else 0\n",
    "        print(f\"   ‚Ä¢ {tema}: {stats['correctos']}/{stats['total']} correctos ({precision_tema:.1f}%)\")\n",
    "    \n",
    "    # Recomendaciones\n",
    "    print(f\"\\nüí° RECOMENDACIONES:\")\n",
    "    if resultados['metricas']['accuracy'] < 0.7:\n",
    "        print(f\"   ‚Ä¢ La exactitud est√° por debajo del 70%. Considera ajustar los umbrales de clasificaci√≥n.\")\n",
    "    if resultados['metricas']['precision'] < 0.7:\n",
    "        print(f\"   ‚Ä¢ La precisi√≥n es baja. Hay muchos falsos positivos (noticias falsas clasificadas como verdaderas).\")\n",
    "    if resultados['metricas']['recall'] < 0.7:\n",
    "        print(f\"   ‚Ä¢ El recall es bajo. Se est√°n perdiendo muchas noticias verdaderas (falsos negativos).\")\n",
    "    \n",
    "    print(f\"\\nüìã Para mejorar el rendimiento:\")\n",
    "    print(f\"   1. Revisar manualmente los archivos mal clasificados\")\n",
    "    print(f\"   2. Ajustar los prompts de verificaci√≥n de veracidad\")\n",
    "    print(f\"   3. Considerar usar un modelo m√°s especializado\")\n",
    "    print(f\"   4. Aumentar el tama√±o del conjunto de datos de entrenamiento\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "576822d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def guardar_respuesta(tema, pregunta, respuesta, verificacion=None):\n",
    "    \"\"\"Guardar la pregunta y respuesta en un archivo de historial.\"\"\"\n",
    "    try:\n",
    "        historial = []\n",
    "        fecha = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        registro = {\n",
    "            \"fecha\": fecha,\n",
    "            \"tema\": tema,\n",
    "            \"pregunta\": pregunta,\n",
    "            \"respuesta\": respuesta\n",
    "        }\n",
    "        if verificacion:\n",
    "            registro[\"verificacion\"] = verificacion\n",
    "        os.makedirs(\"historial\", exist_ok=True)\n",
    "        filename = f\"historial/historial_{datetime.now().strftime('%Y%m%d')}.json\"\n",
    "        if os.path.exists(filename):\n",
    "            with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "                try:\n",
    "                    historial = json.load(f)\n",
    "                except:\n",
    "                    historial = []\n",
    "        historial.append(registro)\n",
    "        with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(historial, f, ensure_ascii=False, indent=2)\n",
    "        print(f\"Respuesta guardada en {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al guardar respuesta: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a2f406",
   "metadata": {},
   "source": [
    "<!-- Secci√≥n de c√≥digo 14 -->\n",
    "## üöÄ Bucle principal de ejecuci√≥n interactiva\n",
    "\n",
    "- Al iniciar, muestra informaci√≥n sobre el sistema y el modo de operaci√≥n (con o sin transformers, claves API configuradas).\n",
    "- Presenta un men√∫ con opciones para el usuario:\n",
    "  1. Hacer una pregunta sobre un tema (usa chatbot tem√°tico, busca noticias, opci√≥n de verificaci√≥n).\n",
    "  2. Analizar un PDF y detectar informaci√≥n falsa (extrae texto, detecta tema, sentimiento, verifica veracidad, extrae afirmaciones y permite su verificaci√≥n individual).\n",
    "  3. Buscar noticias sobre un tema espec√≠fico (muestra resultados, permite verificar noticias y preguntar sobre ellas).\n",
    "  4. Verificar una afirmaci√≥n espec√≠fica (verificaci√≥n puntual con explicaci√≥n).\n",
    "  - Opci√≥n para salir del programa.\n",
    "\n",
    "- Cada opci√≥n gu√≠a al usuario mediante entradas y muestra resultados claros y estructurados.\n",
    "- Maneja errores b√°sicos en entradas y da feedback en consola.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "eb7c5ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sistema IA con APIs de Noticias, An√°lisis de PDFs y Verificaci√≥n de Hechos\n",
      "------------------------------------------------------------\n",
      "\n",
      "Selecciona una opci√≥n:\n",
      "1. Hacer una pregunta sobre un tema\n",
      "2. Analizar un PDF y detectar informaci√≥n falsa\n",
      "3. Buscar noticias sobre un tema espec√≠fico\n",
      "4. Verificar una afirmaci√≥n espec√≠fica\n",
      "5. An√°lisis masivo de archivos (20 archivos: 10 verdaderos + 10 falsos)\n",
      "salir. Salir del programa\n",
      "\n",
      "Extrayendo texto del PDF...\n",
      "\n",
      "Vista previa del texto:\n",
      " \n",
      "21 \n",
      "   Vol. 2, n¬∞ 13,  5 de enero de 2021 \n",
      " ART√çCULO ORIGINAL  \n",
      "COVID-19: la gran pandemia de 2020# \n",
      "Samuel Ponce de Le√≥n Rosales& \n",
      "Coordinador del Programa Universitario de Investigaci√≥n en Salud, ...\n",
      "\n",
      "Analizando tema del documento...\n",
      "Tema principal detectado: COVID-19 (confianza: 0.88)\n",
      "Sentimiento general del texto: POSITIVO (confianza: 0.51)\n",
      "\n",
      "Verificando veracidad del contenido (esto puede tomar un momento)...\n",
      "\n",
      "üîç AN√ÅLISIS DE VERACIDAD: MAYORMENTE VERDADERO\n",
      "üìä Nivel de confianza: 75.0%\n",
      "\n",
      "‚úÖ No se detectaron problemas significativos de veracidad en el documento.\n",
      "\n",
      "Extrayendo afirmaciones principales del documento...\n",
      "\n",
      "Afirmaciones principales identificadas:\n",
      "  1. La definici√≥n de epidemia se refiere a la ocurrencia de una enfermedad por encima de lo esperado, con un agente infeccioso que tiene una capacidad de transmisi√≥n (R0) mayor a 1.\n",
      "  2. Una pandemia es una epidemia que est√° ampliamente extendida.\n",
      "  3. La sindemia se refiere a la suma de epidemias que tienen un efecto sin√©rgico y coinciden en el tiempo, como el COVID-19 y la Influenza.\n",
      "  4. La plaga de Atenas (430 A.C.) caus√≥ la muerte del 30% de la poblaci√≥n de Atenas y tuvo un impacto en la guerra del Peloponeso.\n",
      "  5. La Peste Negra fue responsable de la muerte de m√°s de un tercio de la poblaci√≥n de Europa y tuvo repercusiones sociales y econ√≥micas significativas.\n",
      "\n",
      "Buscando informaci√≥n adicional sobre 'COVID-19'...\n",
      "Encontradas 5 noticias relacionadas con el tema.\n",
      "\n",
      "Selecciona una opci√≥n:\n",
      "1. Hacer una pregunta sobre un tema\n",
      "2. Analizar un PDF y detectar informaci√≥n falsa\n",
      "3. Buscar noticias sobre un tema espec√≠fico\n",
      "4. Verificar una afirmaci√≥n espec√≠fica\n",
      "5. An√°lisis masivo de archivos (20 archivos: 10 verdaderos + 10 falsos)\n",
      "salir. Salir del programa\n",
      "Opci√≥n inv√°lida. Por favor, intenta de nuevo.\n",
      "\n",
      "Selecciona una opci√≥n:\n",
      "1. Hacer una pregunta sobre un tema\n",
      "2. Analizar un PDF y detectar informaci√≥n falsa\n",
      "3. Buscar noticias sobre un tema espec√≠fico\n",
      "4. Verificar una afirmaci√≥n espec√≠fica\n",
      "5. An√°lisis masivo de archivos (20 archivos: 10 verdaderos + 10 falsos)\n",
      "salir. Salir del programa\n",
      "Opci√≥n inv√°lida. Por favor, intenta de nuevo.\n",
      "\n",
      "Selecciona una opci√≥n:\n",
      "1. Hacer una pregunta sobre un tema\n",
      "2. Analizar un PDF y detectar informaci√≥n falsa\n",
      "3. Buscar noticias sobre un tema espec√≠fico\n",
      "4. Verificar una afirmaci√≥n espec√≠fica\n",
      "5. An√°lisis masivo de archivos (20 archivos: 10 verdaderos + 10 falsos)\n",
      "salir. Salir del programa\n",
      "¬°Gracias por usar el sistema!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"Sistema IA con APIs de Noticias, An√°lisis de PDFs y Verificaci√≥n de Hechos\")\n",
    "    print(\"-\" * 60)\n",
    "    if not USE_TRANSFORMERS:\n",
    "        print(\"MODO B√ÅSICO: Funcionando sin modelos de transformers\")\n",
    "        print(\"Algunas funcionalidades como an√°lisis avanzado de sentimiento y clasificaci√≥n de temas ser√°n limitadas.\")\n",
    "    if not NEWS_API_KEY and not GNEWS_API_KEY:\n",
    "        print(\"ADVERTENCIA: No has configurado claves para APIs de noticias.\")\n",
    "        print(\"Las funciones de b√∫squeda de noticias ser√°n limitadas.\")\n",
    "        print(\"Obt√©n una clave gratuita en: https://newsapi.org/ o https://gnews.io/\")\n",
    "        print(\"-\" * 60)\n",
    "    while True:\n",
    "        print(\"\\nSelecciona una opci√≥n:\")\n",
    "        print(\"1. Hacer una pregunta sobre un tema\")\n",
    "        print(\"2. Analizar un PDF y detectar informaci√≥n falsa\")\n",
    "        print(\"3. Buscar noticias sobre un tema espec√≠fico\")\n",
    "        print(\"4. Verificar una afirmaci√≥n espec√≠fica\")\n",
    "        print(\"5. An√°lisis masivo de archivos (20 archivos: 10 verdaderos + 10 falsos)\")\n",
    "        print(\"salir. Salir del programa\")\n",
    "        modo = input(\"\\nOpci√≥n: \")\n",
    "        if modo.lower() in ['salir', 'exit', 'quit']:\n",
    "            print(\"¬°Gracias por usar el sistema!\")\n",
    "            break\n",
    "        if modo == '1':\n",
    "            tema = input(\"¬øSobre qu√© tema quieres hacer tu pregunta? \")\n",
    "            pregunta = input(\"Tu pregunta: \")\n",
    "            verificar_flag = input(\"¬øQuieres verificar la veracidad de la respuesta? (s/n): \").lower() in ['s','si','s√≠']\n",
    "            print(f\"\\nBuscando informaci√≥n reciente sobre '{tema}'...\")\n",
    "            noticias = buscar_noticias(tema)\n",
    "            if noticias:\n",
    "                print(f\"Encontradas {len(noticias)} noticias relacionadas.\")\n",
    "            else:\n",
    "                print(\"No se encontraron noticias relacionadas.\")\n",
    "            respuesta = chatbot_tematico(pregunta, tema=tema, noticias=noticias, verificar=verificar_flag)\n",
    "            print(\"\\nRespuesta:\")\n",
    "            print(respuesta)\n",
    "            guardar_respuesta(tema, pregunta, respuesta)\n",
    "        elif modo == '2':\n",
    "            ruta_pdf = input(\"Ruta completa del PDF: \")\n",
    "            print(\"\\nExtrayendo texto del PDF...\")\n",
    "            texto_extraido = extraer_texto_pdf(ruta_pdf)\n",
    "            if not texto_extraido:\n",
    "                print(\"No se pudo extraer texto del PDF. Verifica la ruta e intenta de nuevo.\")\n",
    "                continue\n",
    "            vista_previa = texto_extraido[:200] + \"...\" if len(texto_extraido) > 200 else texto_extraido\n",
    "            print(f\"\\nVista previa del texto:\\n{vista_previa}\\n\")\n",
    "            print(\"Analizando tema del documento...\")\n",
    "            tema_detectado, confianza_tema = detectar_tema(texto_extraido)\n",
    "            print(f\"Tema principal detectado: {tema_detectado} (confianza: {confianza_tema:.2f})\")\n",
    "            sentimiento, conf_sentimiento = analizar_sentimiento(texto_extraido[:512])\n",
    "            print(f\"Sentimiento general del texto: {sentimiento.upper()} (confianza: {conf_sentimiento:.2f})\")\n",
    "            print(\"\\nVerificando veracidad del contenido (esto puede tomar un momento)...\")\n",
    "            resultado_verificacion = verificar_veracidad(texto_extraido, tema=tema_detectado)\n",
    "            print(f\"\\nüîç AN√ÅLISIS DE VERACIDAD: {resultado_verificacion['veracidad'].upper()}\")\n",
    "            print(f\"üìä Nivel de confianza: {resultado_verificacion['confianza']*100:.1f}%\")\n",
    "            if resultado_verificacion['veracidad'] in [\"Falso\", \"Mayormente falso\", \"Parcialmente verdadero\"]:\n",
    "                print(\"\\n‚ö†Ô∏è Se detectaron posibles informaciones falsas o enga√±osas:\")\n",
    "                for i, razon in enumerate(resultado_verificacion['razones'], 1):\n",
    "                    print(f\"  {i}. {razon}\")\n",
    "            else:\n",
    "                print(\"\\n‚úÖ No se detectaron problemas significativos de veracidad en el documento.\")\n",
    "            print(\"\\nExtrayendo afirmaciones principales del documento...\")\n",
    "            afirmaciones = extraer_afirmaciones(texto_extraido)\n",
    "            if afirmaciones:\n",
    "                print(\"\\nAfirmaciones principales identificadas:\")\n",
    "                for i, afirmacion in enumerate(afirmaciones, 1):\n",
    "                    print(f\"  {i}. {afirmacion}\")\n",
    "                verificar_mas = input(\"\\n¬øQuieres verificar alguna afirmaci√≥n espec√≠fica? (s/n):\").lower() in ['s','si','s√≠']\n",
    "                if verificar_mas:\n",
    "                    while True:\n",
    "                        idx_input = input(\"Ingresa el n√∫mero de la afirmaci√≥n a verificar (0 para salir): \")\n",
    "                        try:\n",
    "                            idx = int(idx_input)\n",
    "                            if idx == 0: break\n",
    "                            if 1 <= idx <= len(afirmaciones):\n",
    "                                print(f\"\\nVerificando: '{afirmaciones[idx-1]}'...\")\n",
    "                                res_aff = verificar_afirmacion(afirmaciones[idx-1], tema=tema_detectado)\n",
    "                                print(f\"Veredicto: {res_aff['veracidad']}\")\n",
    "                                print(f\"An√°lisis:\\n{res_aff['explicacion']}\")\n",
    "                            else:\n",
    "                                print(\"N√∫mero de afirmaci√≥n inv√°lido.\")\n",
    "                        except ValueError:\n",
    "                            print(\"Por favor ingresa un n√∫mero v√°lido.\")\n",
    "            print(f\"\\nBuscando informaci√≥n adicional sobre '{tema_detectado}'...\")\n",
    "            noticias = buscar_noticias(tema_detectado)\n",
    "            if noticias:\n",
    "                print(f\"Encontradas {len(noticias)} noticias relacionadas con el tema.\")\n",
    "            while True:\n",
    "                pregunta = input(\"\\nHaz una pregunta sobre el documento (o escribe 'salir' para volver): \")\n",
    "                if pregunta.lower() in ['salir','exit','quit']: break\n",
    "                respuesta = chatbot_tematico(pregunta, tema=tema_detectado, contexto_texto=texto_extraido, noticias=noticias, verificar=True)\n",
    "                print(\"\\nRespuesta:\")\n",
    "                print(respuesta)\n",
    "                guardar_respuesta(tema_detectado, pregunta, respuesta, verificacion=resultado_verificacion['veracidad'])\n",
    "        elif modo == '3':\n",
    "            tema = input(\"¬øSobre qu√© tema quieres buscar noticias? \")\n",
    "            cantidad_input = input(\"¬øCu√°ntas noticias quieres ver? (1-10): \")\n",
    "            try:\n",
    "                cantidad = int(cantidad_input)\n",
    "                if cantidad < 1 or cantidad > 10: cantidad = 5\n",
    "            except:\n",
    "                cantidad = 5\n",
    "            print(f\"\\nBuscando {cantidad} noticias sobre '{tema}'...\")\n",
    "            noticias = buscar_noticias(tema, cantidad)\n",
    "            if noticias:\n",
    "                print(f\"\\nSe encontraron {len(noticias)} noticias:\")\n",
    "                for i, noti in enumerate(noticias,1):\n",
    "                    print(f\"\\n{i}. {noti['titulo']}\")\n",
    "                    print(f\"   {noti['descripcion']}\")\n",
    "                    print(f\"   Fuente: {noti['fuente']} - Fecha: {noti['fecha']}\")\n",
    "                    print(f\"   URL: {noti['url']}\")\n",
    "                try:\n",
    "                    idx_v = int(input(\"\\n¬øQuieres verificar alguna noticia? Ingresa el n√∫mero (0 para ninguna): \"))\n",
    "                    if 1 <= idx_v <= len(noticias):\n",
    "                        print(f\"\\nVerificando noticia {idx_v}: '{noticias[idx_v-1]['titulo']}'...\")\n",
    "                        res_noticia = verificar_noticia(noticias[idx_v-1])\n",
    "                        print(f\"\\nüîç AN√ÅLISIS DE VERACIDAD: {res_noticia['veracidad'].upper()}\")\n",
    "                        print(f\"üìä Nivel de confianza: {res_noticia['confianza']*100:.1f}%\")\n",
    "                        if res_noticia['veracidad'] in [\"Falso\",\"Mayormente falso\",\"Parcialmente verdadero\"]:\n",
    "                            print(\"\\n‚ö†Ô∏è Motivos de preocupaci√≥n:\")\n",
    "                            for i, r in enumerate(res_noticia['razones'],1): print(f\"  {i}. {r}\")\n",
    "                        else:\n",
    "                            print(\"\\n‚úÖ Esta noticia parece confiable.\")\n",
    "                except:\n",
    "                    pass\n",
    "                while True:\n",
    "                    preg2 = input(\"\\n¬øQuieres hacer una pregunta sobre estas noticias? (escribe 'salir' para volver): \")\n",
    "                    if preg2.lower() in ['salir','exit','quit','no']: break\n",
    "                    resp2 = chatbot_tematico(preg2, tema=tema, noticias=noticias, verificar=True)\n",
    "                    print(\"\\nRespuesta:\")\n",
    "                    print(resp2)\n",
    "                    guardar_respuesta(tema, preg2, resp2)\n",
    "            else:\n",
    "                print(\"No se encontraron noticias sobre ese tema.\")\n",
    "        elif modo == '4':\n",
    "            afirm = input(\"Escribe la afirmaci√≥n que quieres verificar: \")\n",
    "            tema_aff = input(\"¬øSobre qu√© tema est√° relacionada esta afirmaci√≥n? (opcional): \") or None\n",
    "            if afirm:\n",
    "                print(\"\\nVerificando afirmaci√≥n...\")\n",
    "                res_aff = verificar_afirmacion(afirm, tema=tema_aff)\n",
    "                print(f\"\\nüîç VEREDICTO: {res_aff['veracidad'].upper()}\")\n",
    "                print(f\"\\nAn√°lisis detallado:\\n{res_aff['explicacion']}\")\n",
    "            else:\n",
    "                print(\"No has proporcionado ninguna afirmaci√≥n para verificar.\")\n",
    "        elif modo == '5':\n",
    "            print(\"\\nüìä AN√ÅLISIS MASIVO DE ARCHIVOS - EVALUACI√ìN DE RENDIMIENTO\")\n",
    "            print(\"=\" * 55)\n",
    "            print(\"Este an√°lisis requiere dos directorios:\")\n",
    "            print(\"1. Directorio con archivos de noticias VERDADERAS (hasta 10 archivos)\")\n",
    "            print(\"2. Directorio con archivos de noticias FALSAS (hasta 10 archivos)\")\n",
    "            print(\"\\nFormatos soportados: .txt, .pdf\\n\")\n",
    "            \n",
    "            dir_verdaderas = input(\"Ruta del directorio con noticias VERDADERAS: \").strip('\"')\n",
    "            dir_falsas = input(\"Ruta del directorio con noticias FALSAS: \").strip('\"')\n",
    "            \n",
    "            # Validar que los directorios existan\n",
    "            if not os.path.exists(dir_verdaderas):\n",
    "                print(f\"‚ùå Error: No se encontr√≥ el directorio '{dir_verdaderas}'\")\n",
    "                continue\n",
    "            if not os.path.exists(dir_falsas):\n",
    "                print(f\"‚ùå Error: No se encontr√≥ el directorio '{dir_falsas}'\")\n",
    "                continue\n",
    "            \n",
    "            max_archivos_input = input(\"¬øCu√°ntos archivos procesar por categor√≠a? (m√°ximo 10, por defecto 10): \")\n",
    "            try:\n",
    "                max_archivos = int(max_archivos_input) if max_archivos_input else 10\n",
    "                max_archivos = min(max_archivos, 10)  # L√≠mite m√°ximo\n",
    "            except:\n",
    "                max_archivos = 10\n",
    "            \n",
    "            print(f\"\\nüöÄ Iniciando an√°lisis de hasta {max_archivos} archivos por categor√≠a...\")\n",
    "            print(\"‚è∞ Este proceso puede tomar varios minutos...\\n\")\n",
    "            \n",
    "            try:\n",
    "                # Ejecutar an√°lisis masivo\n",
    "                resultados = analisis_masivo_archivos(dir_verdaderas, dir_falsas, max_archivos)\n",
    "                \n",
    "                # Mostrar reporte detallado\n",
    "                mostrar_reporte_analisis(resultados)\n",
    "                \n",
    "                # Preguntar si quiere guardar los resultados\n",
    "                guardar = input(\"\\nüíæ ¬øQuieres guardar estos resultados en un archivo JSON? (s/n): \").lower() in ['s','si','s√≠']\n",
    "                if guardar:\n",
    "                    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                    filename = f\"analisis_masivo_{timestamp}.json\"\n",
    "                    try:\n",
    "                        with open(filename, 'w', encoding='utf-8') as f:\n",
    "                            json.dump(resultados, f, ensure_ascii=False, indent=2, default=str)\n",
    "                        print(f\"‚úÖ Resultados guardados en: {filename}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"‚ùå Error al guardar archivo: {e}\")\n",
    "                \n",
    "                # Opci√≥n de an√°lisis interactivo\n",
    "                while True:\n",
    "                    analisis_extra = input(\"\\nüîç ¬øQuieres revisar alg√∫n archivo espec√≠fico en detalle? (s/n): \").lower()\n",
    "                    if analisis_extra not in ['s','si','s√≠']:\n",
    "                        break\n",
    "                    \n",
    "                    print(\"\\nArchivos disponibles:\")\n",
    "                    todos_archivos = []\n",
    "                    \n",
    "                    print(\"\\nüì∞ Noticias VERDADERAS:\")\n",
    "                    for i, detalle in enumerate(resultados['verdaderas']['detalles'], 1):\n",
    "                        estado = \"‚úÖ\" if detalle['clasificacion_correcta'] else \"‚ùå\"\n",
    "                        print(f\"  {len(todos_archivos)+1}. {estado} {detalle['archivo']} - {detalle['veracidad']} ({detalle['confianza_veracidad']*100:.1f}%)\")\n",
    "                        todos_archivos.append(('verdaderas', detalle))\n",
    "                    \n",
    "                    print(\"\\nüö´ Noticias FALSAS:\")\n",
    "                    for i, detalle in enumerate(resultados['falsas']['detalles'], 1):\n",
    "                        estado = \"‚úÖ\" if detalle['clasificacion_correcta'] else \"‚ùå\"\n",
    "                        print(f\"  {len(todos_archivos)+1}. {estado} {detalle['archivo']} - {detalle['veracidad']} ({detalle['confianza_veracidad']*100:.1f}%)\")\n",
    "                        todos_archivos.append(('falsas', detalle))\n",
    "                    \n",
    "                    try:\n",
    "                        idx = int(input(f\"\\nSelecciona un archivo (1-{len(todos_archivos)}, 0 para salir): \"))\n",
    "                        if idx == 0:\n",
    "                            break\n",
    "                        if 1 <= idx <= len(todos_archivos):\n",
    "                            categoria, detalle = todos_archivos[idx-1]\n",
    "                            print(f\"\\nüìÑ AN√ÅLISIS DETALLADO: {detalle['archivo']}\")\n",
    "                            print(f\"{'='*50}\")\n",
    "                            print(f\"Categor√≠a real: {categoria.upper()}\")\n",
    "                            print(f\"Tema detectado: {detalle['tema']} (confianza: {detalle['confianza_tema']:.2f})\")\n",
    "                            print(f\"Veracidad detectada: {detalle['veracidad']}\")\n",
    "                            print(f\"Confianza en veracidad: {detalle['confianza_veracidad']*100:.1f}%\")\n",
    "                            print(f\"Clasificaci√≥n correcta: {'‚úÖ S√ç' if detalle['clasificacion_correcta'] else '‚ùå NO'}\")\n",
    "                            print(f\"\\nVista previa del contenido:\")\n",
    "                            print(f\"{'-'*30}\")\n",
    "                            print(detalle['contenido_preview'])\n",
    "                        else:\n",
    "                            print(\"N√∫mero inv√°lido.\")\n",
    "                    except ValueError:\n",
    "                        print(\"Por favor ingresa un n√∫mero v√°lido.\")\n",
    "                        \n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error durante el an√°lisis masivo: {e}\")\n",
    "                print(\"Verifica que los directorios contengan archivos v√°lidos (.txt o .pdf)\")\n",
    "        else:\n",
    "            print(\"Opci√≥n inv√°lida. Por favor, intenta de nuevo.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
